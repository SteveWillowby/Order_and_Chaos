\documentclass{article}

\usepackage{bbm}
\usepackage{amsmath}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{subcaption}

\geometry{margin=1in}

\begin{document}

\title{SCHENO's Binaries and C++ Classes}

\author{Justus Hibshman}

\date{April 2024}

\maketitle

\vspace{2cm}

\section*{Outline}

\begin{itemize}
    \item \ref{sec:nt_intro} Introduction to SCHENO
    \item \ref{sec:features} Features of this Repository
    \item \ref{sec:setup} Setup and Compilation
    \item \ref{sec:binaries} Using the Executables
    \item \ref{sec:interface} Interface
\end{itemize}


\newpage

\section{Introduction to SCHENO}\label{sec:nt_intro}

The core idea behind \verb|SCHENO| is that real-world graphs are messy manifestations of underlying patterns. \verb|SCHENO| offers a principled way to measure how well you've done at uncovering those patterns.

The formal definitions and explanations can be read in the paper located at: \url{http://arxiv.org/abs/2404.13489}

\subsection{Notation}

Let $A$ and $B$ be sets. I use $A \oplus B$ to mean $(A \setminus B) \cap (B \setminus A)$. It can be thought of as analogous the logical XOR operation. The set $A \oplus B$ includes the things that are in exactly one of $A$ or $B$, but not both.

Similarly, given two graphs $G_1 = (V, E_1)$ and $G_2 = (V, E_2)$, I define $G_1 \oplus G_2$ to be the graph $(V, E_1 \oplus E_2)$.

Lastly, given a graph $G = (V, E)$, I define a ``Schema-Noise Decomposition'' of $G$ to be two graphs $S = (V, E_S)$ and $N = (V, E_N)$ such that $S \oplus N = G$. In other words, if you start with the schema $S$ and then ``XOR'' its edges with the noise edges, you get the graph $G$.


\section{Features of This Repository}\label{sec:features}

This repository offers the following components:

\begin{enumerate}
    \item An efficient \verb|C++| implementation of the \verb|SCHENO| scoring function, available in a static library and as an executable.
    \item Code to obtain \verb|SCHENO| scores for many schema-noise decompositions in parallel.
    \item A genetic algorithm "\verb|SCHENO_ga|" that searches for good schema-noise decompositions, guided by \verb|SCHENO| as its fitness function.
    \item Elegant \verb|C++| wrappers around the \verb|nauty| and \verb|traces| isomorphism algorithms\footnote{These wrappers are available in a standalone repository at \url{https://github.com/schemanoise/Nauty_and_Traces}}.\footnote{Frankly, these wrappers provide a much more elegant code interface than the rest of the SCHENO code. If you find the SCHENO code interface crufty, you still may very well like the isomorphism interface.}.
\end{enumerate}

\newpage

\section{Setup and Compilation}\label{sec:setup}

Setting up the code is a simple as running \verb|./setup.sh| to compile the libraries and then running \verb|./compile.sh| to compile the executables.

Whatever custom code you write will need to include the file \verb|scheno.h| from inside the \verb|scheno| folder.

To compile your own code, you will need to include the static library \verb|scheno.a| located inside the \verb|scheno| folder.

Example compilation:

\begin{verbatim}
    g++ -Wall -Wextra -o my_output -std=c++11 my_program.cpp scheno/scheno.a
\end{verbatim}

\newpage

\section{Using the Executables}\label{sec:binaries}

\subsection{SCHENO\_score}

This program requires two things as input: a graph $G = (V, E)$ given as an edgelist and a ``noise set'' $N = (V, E_N)$ also given as an edge list. The schema is inferred to be $S = G \oplus N$, which is the only edge set such that $S \oplus N = G$.

It gives the SCHENO score for the schema-noise decomposition $S$, $N$. It also displays some information about the number of automorphisms of $G$ and $S$. 

Finally, it also reports how much of the decomposition score is due to taking $G$ and deleting all the edges to some nodes, thereby forming ``singletons'' which are all structurally equivalent to each other, vs. how much of the decomposition score is due to the other ways the schema differs from the graph.

There are many optional flags you can use when running the program. You can see a description of all of them by running \verb|SCHENO_score -h|

A few of the most important flags are:

\begin{itemize}
    \item \verb|-nodes <arg>| -- This flag allows you to specify to text file with a list of node IDs. That way, if your edgelist does not have all the nodes you want, they can be included.
    \item \verb|-d| and \verb|-u| -- These flags allow you to specify whether the graph is directed or undirected. Undirected is the default.
    \item \verb|-approx| -- Causes the program to use a heuristic isomorphism program which might not always return the correct result. This is often correct, and can be significantly faster, particularly if the graph is large enough. If the graph is small enough, it can actually be slower. See more details at the end of the other manual, \verb|nauty_and_traces_wrappers.pdf|.
\end{itemize}

\subsection{SCHENO\_ga}

This program takes a single graph as input in the form of an edgelist. It tries to find a good schema-noise decomposition of the graph.

The program also takes a filepath argument \verb|-o <f>| to specify its output. It will produce three files: \verb|<f>_graph.txt|, \verb|<f>_noise.txt|, \verb|<f>_nodes.txt|. The graph file stores the schema. The noise file stores the noise. Neither file is guaranteed to reference all the nodes in the original graph -- hence the nodelist output file\footnote{Also, output node IDs might not line up with the original input edgelist's node IDs if the original IDs were not 0 through $n - 1$.}.

There are many optional flags you can use when running the program. You can see a description of all of them by running \verb|SCHENO_ga -h|

A few of the most important flags are:

\begin{itemize}
    \item \verb|-nodes <arg>| -- This flag allows you to specify to text file with a list of node IDs. That way, if your edgelist does not have all the nodes you want, they can be included.
    \item \verb|-d| and \verb|-u| -- These flags allow you to specify whether the graph is directed or undirected. Undirected is the default.
    \item \verb|-n_itr <arg>| -- How many iterations the genetic algorithm runs for
    \item \verb|-topk <arg>| -- The number of top-scoring noise sets to report on the command line (only the very best decomposition is written to a file)
    \item \verb|-sample_heuristic| -- \verb|SCHENO_ga| can use a heuristic when randomly sampling edges to add to the noise set. This feature is experimental; it requires a hefty pre-computation step and is not guaranteed to improve performance. You can turn this feature on with this flag.
    \item \verb|-nt| -- Number of threads to use. Defaults to 0, which means max parallelism available on the machine.
    \item \verb|-approx_iso| -- Lets the \verb|SCHENO| score computation make use of an approximate isomorphism algorithm. This can sometimes speed up the computation on medium and large graphs.
    \item \verb|-seed <arg>| -- Lets you specify a starting schema-noise decomposition by giving it an edgelist that corresponds to a noise set. The algorithm will use this as its starting point.
    \item \verb|-legal_noise <arg>| -- Lets you specify limits on which edges and non-edges can be considered as noise. The argument should be a filename; the file should contain a list of node pairs (i.e. an edgelist).
\end{itemize}

\newpage

\section{Interface}\label{sec:interface}

\subsection{What You Need for the Scoring Function}

The \verb|SCHENO| scoring function has the following interface:

\begin{verbatim}
long double score(NTSparseGraph& g,
                  const CombinatoricUtility& comb_util,
                  const Coloring<int>& node_orbit_coloring,
                  const Coloring<Edge, EdgeHash>& edge_orbit_coloring,
                  Coloring<Edge, EdgeHash>& editable_edge_orbit_coloring,
                  const std::unordered_set<Edge,EdgeHash>& edge_additions,
                  const std::unordered_set<Edge,EdgeHash>& edge_removals,
                  const long double log2_p_plus,
                  const long double log2_p_minus,
                  const long double log2_1_minus_p_plus,
                  const long double log2_1_minus_p_minus,
                  const size_t max_change,
                  bool full_iso);
\end{verbatim}

You can see an example of using it's sister function, \verb|score_breakdown()| in the file \verb|SCHENO_score.cpp|. The two functions take exactly the same input arguments.

The input graph is \verb|g|.

The \verb|CombinatoricUtility| class is basically a storage unit for math computations that are likely to come up again and again if you score many different decompositions. It's discussed in Section~\ref{sec:comb_util}.

The arguments \verb|node_orbit_coloring| and \verb|edge_orbit_coloring| as well as \verb|editable_edge_orbit_coloring| are required for efficiency reasons. Precomputing them speeds things up if you score multiple different decompositions for a single graph. These colorings can be produced with a call to one of the isomorphism algorithms available in the repository, \verb|nauty|, \verb|traces|, and \verb|fake_iso|. Essentially, the inputs record which nodes and edges in the original graph are structurally equivalent to each other. Make sure that \verb|editable_edge_orbit_coloring| is a different object from \verb|edge_orbit_coloring|.

The \verb|edge_additions| and \verb|edge_removals| arguments represent the noise set being considered in the schema-noise decomposition. They are the edges added to and removed from \verb|g| respectively.

The next four inputs, \verb|log2_p_plus|, \verb|log2_p_minus|, \verb|log2_1_minus_p_plus|, \verb|log2_1_minus_p_minus| are parameters that affect the scoring function's calculation. They affect how likely noise is considered to be. \verb|log2_p_plus| is the base-2 logarithm of the probability that an edge is randomly added to the \emph{schema} (randomly \emph{removed} from \verb|g|). \verb|log2_p_minus| is the base-2 logarithm of the probability that an edge is randomly removed from the \emph{schema} (randomly \emph{added} to \verb|g|). It is strongly recommended that you stick with the default values, as discussed in Section~\ref{sec:log_probs}.

The parameter \verb|max_change| is the maximum number of node pairs you want to allow in the noise set. Any noise set with more than \verb|max_change| node pairs will automatically receive a score of $-\infty$.

Finally, \verb|full_iso| indicates whether or not the scoring function should use a full-fledged isomorphism algorithm (in this case \verb|traces|) or an approximate algorithm ``\verb|fake_iso|.'' A value of \verb|true| means \verb|traces|; a value of \verb|false| means \verb|fake_iso|. The \verb|fake_iso| algorithm often returns the correct result and can be much faster on large enough graphs.

The following classes, structs, and functions are important and are discussed at length in the other pdf manual associated with this repository (\verb|nauty_and_traces_wrappers.pdf|):

\begin{itemize}
    \item \verb|Graph|, \verb|SparseGraph|, and \verb|NTSparseGraph|
    \item \verb|NautyTracesOptions| and \verb|NautyTracesResults|
    \item \verb|Coloring<T>|
    \item \verb|Edge|
    \item \verb|read_graph()| and \verb|write_graph()|
    \item \verb|nauty()|, \verb|traces()|, and \verb|fake_iso()|
\end{itemize}

\subsection{CombinatoricUtility}\label{sec:comb_util}

The combinatoric utility class pre-computes useful values like the logarithms of factorials. Its constructor takes two inputs:

\begin{verbatim}
CombinatoricUtility(size_t max_e, size_t max_f);
\end{verbatim}

\verb|max_e| must be larger than the max number of edges your graph COULD ever have, including self-loops.

\verb|max_f| must be larger than both of the following:
\begin{itemize}
    \item the max number of edges your graph WILL have PLUS the number of edges you will delete from it
    \item (the max number of edges you COULD have MINUS the number of edges your graph WILL have) PLUS the number of edges you will delete from it
\end{itemize}

It's probably a safe bet to make: \verb|max_f| $\geq$ $\min(3m,$ \verb|max_e| $- (3($\verb|max_e|$ - m)))$ where $m$ is the number of edges.

The constructor for the \verb|CombinatoricUtility| class will take O(\verb|max_e|) time, and the class's data structures will use O(\verb|max_f|) space.

\subsection{Default Log-Prob Parameters}\label{sec:log_probs}

To get the default values for \verb|log2_p_plus|, \verb|log2_p_minus|, \verb|log2_1_minus_p_plus|, and \verb|log2_1_minus_p_minus|, use the function:

\begin{verbatim}
std::vector<long double>
        default_log2_noise_probs(NTSparseGraph& g,
                                 const CombinatoricUtility& comb_util);
\end{verbatim}

It returns a vector of the four log-probabilities \emph{in the following order}:

\begin{itemize}
    \setlength\itemsep{0em}
    \item \verb|log2_p_plus|
    \item \verb|log2_1_minus_p_plus|
    \item \verb|log2_p_minus|
    \item \verb|log2_1_minus_p_minus|
\end{itemize}

\subsection{The Thread-Pool Scorer}

If for some reason you want to score many schema-noise decompositions for the same graph in parallel, you could consider using the \verb|ThreadPoolScorer| class.

It is initialized in much the same way that the scoring function is called (discussed above):

\begin{verbatim}
ThreadPoolScorer(size_t nt, const Graph& g,
                 const CombinatoricUtility& comb_util,
                 const Coloring<int>& node_orbit_coloring,
                 const Coloring<Edge,EdgeHash>& edge_orbit_coloring,
                 long double log2_p_plus,
                 long double log2_p_minus,
                 long double log2_1_minus_p_plus,
                 long double log2_1_minus_p_minus,
                 size_t max_size,
                 bool use_heuristic,
                 bool full_iso);
\end{verbatim}

There are two parameters not asked for in the \verb|score()| function: \verb|nt| and \verb|use_heuristic|. The number \verb|nt| is the number of threads to use. If you pass $0$, the \verb|ThreadPoolScorer| will use the parallelism that the machine offers.

You will almost certainly want to set the \verb|use_heuristic| value to \verb|false|. It was part of an experimental feature to give a fuzzy tie-breaker score meant to say which decompositions were \emph{closer} to getting a better \verb|SCHENO| score even if they had the same \emph{actual} \verb|SCHENO| score.

Once you have initialized your \verb|ThreadPoolScorer| for a particular graph as shown above, you can score decompositions with the function:

\begin{verbatim}
const std::vector<std::pair<long double, long double>>& get_scores(
                         std::vector<std::unique_ptr<EdgeSetPair>> *tasks);
\end{verbatim}

The input \verb|tasks| contains a list of all the different noise sets to be scored.

The output is a vector of pairs of long doubles. The score for task $i$ is the \emph{first} of the two long doubles in the $i$'th output pair.

IMPORTANT: The size of the output vector can be larger than the size of the input vector. Never make use of the output vector's size. Always use \verb|tasks->size()|.

An \verb|EdgeSetPair| is a base class. You will likely want to use the \verb|BasicEdgeSetPair| subclass, which is basically just a wrapper around two sets of edges: one set for noise edges removed from the base graph (i.e. noise edges added to the schema), the other for noise edges added to the base graph (i.e. noise edges deleted from the schema).

A \verb|BasicEdgeSetPair| has the constructor:

\begin{verbatim}
BasicEdgeSetPair(const std::unordered_set<Edge, EdgeHash>& removed,
                 const std::unordered_set<Edge, EdgeHash>& added)
\end{verbatim}

\subsubsection{Esoteric Trivia}

The reason for the class/sub-class functionality is that the genetic algorithm \verb|SCHENO_ga| encodes edges more space-efficiently as integers. That way the \verb|tasks| vector is smaller. When the thread-pool scorer asks for the two edge sets within an edge set pair, the genetic algorithm's \verb|EdgeSetPair| subclass, \verb|GeneEdgeSetPair|, temporarily converts the integers to sets of \verb|Edge| objects.

% \bibliographystyle{plain}
% \bibliography{references}


% \begin{appendices}

% \section{An Appendix}

% \end{appendices}

\end{document}
